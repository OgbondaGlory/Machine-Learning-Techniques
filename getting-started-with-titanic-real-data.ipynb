{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd86c95",
   "metadata": {
    "papermill": {
     "duration": 0.007751,
     "end_time": "2022-12-30T04:08:24.535954",
     "exception": false,
     "start_time": "2022-12-30T04:08:24.528203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Importing Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af7f1dbd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:24.551820Z",
     "iopub.status.busy": "2022-12-30T04:08:24.551128Z",
     "iopub.status.idle": "2022-12-30T04:08:24.564253Z",
     "shell.execute_reply": "2022-12-30T04:08:24.562935Z"
    },
    "papermill": {
     "duration": 0.023601,
     "end_time": "2022-12-30T04:08:24.566393",
     "exception": false,
     "start_time": "2022-12-30T04:08:24.542792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1af8c3",
   "metadata": {
    "papermill": {
     "duration": 0.006663,
     "end_time": "2022-12-30T04:08:24.580509",
     "exception": false,
     "start_time": "2022-12-30T04:08:24.573846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Testing data loading step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9deb04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:24.596417Z",
     "iopub.status.busy": "2022-12-30T04:08:24.596040Z",
     "iopub.status.idle": "2022-12-30T04:08:24.634366Z",
     "shell.execute_reply": "2022-12-30T04:08:24.633008Z"
    },
    "papermill": {
     "duration": 0.049013,
     "end_time": "2022-12-30T04:08:24.637004",
     "exception": false,
     "start_time": "2022-12-30T04:08:24.587991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the testing dataset\n",
    "X_test_full = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "\n",
    "X_test_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3206c1",
   "metadata": {
    "papermill": {
     "duration": 0.006949,
     "end_time": "2022-12-30T04:08:24.651406",
     "exception": false,
     "start_time": "2022-12-30T04:08:24.644457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Training data loading step. We are at a point where we split the training and validation data in train_X, val_X, train_y, val_y.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427380d1",
   "metadata": {
    "papermill": {
     "duration": 0.008201,
     "end_time": "2022-12-30T04:08:24.666845",
     "exception": false,
     "start_time": "2022-12-30T04:08:24.658644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we will experiment with one-hot encoding.  But, instead of encoding all of the categorical variables in the dataset, we will only create a one-hot encoding for columns with cardinality less than 10.\n",
    "\n",
    "Run the code cell below without changes to set `low_cardinality_cols` to a Python list containing the columns that will be one-hot encoded.  Likewise, `high_cardinality_cols` contains a list of categorical columns that will be dropped from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3562d72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:24.683094Z",
     "iopub.status.busy": "2022-12-30T04:08:24.682468Z",
     "iopub.status.idle": "2022-12-30T04:08:25.780744Z",
     "shell.execute_reply": "2022-12-30T04:08:25.779129Z"
    },
    "papermill": {
     "duration": 1.109206,
     "end_time": "2022-12-30T04:08:25.783138",
     "exception": false,
     "start_time": "2022-12-30T04:08:24.673932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be one-hot encoded: ['Sex', 'Embarked']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Cabin', 'Name', 'Ticket']\n",
      "\n",
      "Numerical Columns from the dataset: ['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare'] \n",
      "\n",
      "Number of Unique entries : [('Sex', 2), ('Embarked', 3), ('Cabin', 127), ('Ticket', 569), ('Name', 712)]\n"
     ]
    }
   ],
   "source": [
    "#Importing the training dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Declaring X and y vairiables\n",
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "y = train_data[\"Survived\"]\n",
    "X = train_data.drop(['Survived'], axis=1)\n",
    "\n",
    "# Divide data into training and validation subsets\n",
    "# split data into training and validation data, for both features and target\n",
    "# The split is based on a random number generator. Supplying a numeric value to\n",
    "# the random_state argument guarantees we get the same split every time we split\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,train_size=0.8, test_size=0.2,random_state = 0)\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Get list of categorical variables\n",
    "s = (train_X.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [col for col in object_cols if train_X[col].nunique() < 10]\n",
    "# Columns that will be dropped from the dataset\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)\n",
    "\n",
    "\n",
    "#Or you can do this if you know the columns to drop\n",
    "# X.drop(['Name', 'Cabin', 'Ticket'], axis=1, inplace=True)\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in train_X.columns if train_X[cname].dtype in ['int64', 'float64']]\n",
    "print('\\nNumerical Columns from the dataset:', numerical_cols,'\\n')\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = low_cardinality_cols + numerical_cols  \n",
    "# my_cols = train_data['Cabin']\n",
    "X_train = train_X[my_cols].copy()\n",
    "X_valid = val_X[my_cols].copy()\n",
    "\n",
    "\n",
    "# # Get number of unique entries in each column with categorical data\n",
    "object_nunique = list(map(lambda col: train_X[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# # # Print number of unique entries by column, in ascending order\n",
    "print('Number of Unique entries :',sorted(d.items(), key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8a28aa",
   "metadata": {
    "papermill": {
     "duration": 0.006753,
     "end_time": "2022-12-30T04:08:25.797167",
     "exception": false,
     "start_time": "2022-12-30T04:08:25.790414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We take a peek at the training data with the head() method below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72ac06b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:25.813037Z",
     "iopub.status.busy": "2022-12-30T04:08:25.812410Z",
     "iopub.status.idle": "2022-12-30T04:08:25.824593Z",
     "shell.execute_reply": "2022-12-30T04:08:25.823412Z"
    },
    "papermill": {
     "duration": 0.022603,
     "end_time": "2022-12-30T04:08:25.826681",
     "exception": false,
     "start_time": "2022-12-30T04:08:25.804078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>141</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15.2458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>440</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "      <td>818</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "      <td>379</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>492</td>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sex Embarked  PassengerId  Pclass   Age  SibSp  Parch     Fare\n",
       "140  female        C          141       3   NaN      0      2  15.2458\n",
       "439    male        S          440       2  31.0      0      0  10.5000\n",
       "817    male        C          818       2  31.0      1      1  37.0042\n",
       "378    male        C          379       3  20.0      0      0   4.0125\n",
       "491    male        S          492       3  21.0      0      0   7.2500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8962fd",
   "metadata": {
    "papermill": {
     "duration": 0.007204,
     "end_time": "2022-12-30T04:08:25.841647",
     "exception": false,
     "start_time": "2022-12-30T04:08:25.834443",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Using Ordinal Encoding**\n",
    "This is a common problem that you'll encounter with real-world data, and there are many approaches to fixing this issue.  For instance, you can write a custom ordinal encoder to deal with new categories.  The simplest approach, however, is to drop the problematic categorical columns.  \n",
    "\n",
    "Run the code cell below to save the problematic columns to a Python list `bad_label_cols`.  Likewise, columns that can be safely ordinal encoded are stored in `good_label_cols`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a1aa64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:25.859018Z",
     "iopub.status.busy": "2022-12-30T04:08:25.858388Z",
     "iopub.status.idle": "2022-12-30T04:08:25.863448Z",
     "shell.execute_reply": "2022-12-30T04:08:25.862817Z"
    },
    "papermill": {
     "duration": 0.015856,
     "end_time": "2022-12-30T04:08:25.865179",
     "exception": false,
     "start_time": "2022-12-30T04:08:25.849323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be ordinal encoded: ['Sex', 'Embarked']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Cabin', 'Name', 'Ticket']\n",
      "\n",
      "Categorical variables:\n",
      "['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "# Columns that can be safely ordinal encoded\n",
    "good_label_cols = low_cardinality_cols\n",
    "        \n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be ordinal encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)\n",
    "print(\"\\nCategorical variables:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe2bfd3",
   "metadata": {
    "papermill": {
     "duration": 0.006896,
     "end_time": "2022-12-30T04:08:25.879381",
     "exception": false,
     "start_time": "2022-12-30T04:08:25.872485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Define Function to Measure Quality of Each Approach**\n",
    "\n",
    "We define a function score_dataset() to compare the three different approaches to dealing with categorical variables. This function reports the mean absolute error (MAE) from a random forest model. In general, we want the MAE to be as low as possible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "004cf5f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:25.895508Z",
     "iopub.status.busy": "2022-12-30T04:08:25.894822Z",
     "iopub.status.idle": "2022-12-30T04:08:26.101151Z",
     "shell.execute_reply": "2022-12-30T04:08:26.100146Z"
    },
    "papermill": {
     "duration": 0.217138,
     "end_time": "2022-12-30T04:08:26.103677",
     "exception": false,
     "start_time": "2022-12-30T04:08:25.886539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, train_y, val_y):\n",
    "    model = RandomForestRegressor(max_leaf_nodes=100, n_estimators=10, random_state=1)\n",
    "    model.fit(X_train, train_y)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(val_y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f5e00a",
   "metadata": {
    "papermill": {
     "duration": 0.007227,
     "end_time": "2022-12-30T04:08:26.118603",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.111376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Before jumping into encoding, we'll investigate the dataset.  Specifically, we'll look at the `'Condition2'` column.  The code cell below prints the unique entries in both the training and validation sets**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23f0c77d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:26.134548Z",
     "iopub.status.busy": "2022-12-30T04:08:26.134168Z",
     "iopub.status.idle": "2022-12-30T04:08:26.137978Z",
     "shell.execute_reply": "2022-12-30T04:08:26.136974Z"
    },
    "papermill": {
     "duration": 0.013861,
     "end_time": "2022-12-30T04:08:26.139665",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.125804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(\"Unique values in 'Condition2' column in training data:\", X_train['Condition2'].unique())\n",
    "# print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Condition2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2089f5b6",
   "metadata": {
    "papermill": {
     "duration": 0.006955,
     "end_time": "2022-12-30T04:08:26.154129",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.147174",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Ordinal Encoding \n",
    "\n",
    "Use the next code cell to ordinal encode the data in `X_train` and `X_valid`.  Set the preprocessed DataFrames to `label_X_train` and `label_X_valid`, respectively.  \n",
    "- We have provided code below to drop the categorical columns in `bad_label_cols` from the dataset. \n",
    "- You should ordinal encode the categorical columns in `good_label_cols`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48c54826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:26.170709Z",
     "iopub.status.busy": "2022-12-30T04:08:26.170174Z",
     "iopub.status.idle": "2022-12-30T04:08:26.180171Z",
     "shell.execute_reply": "2022-12-30T04:08:26.179455Z"
    },
    "papermill": {
     "duration": 0.020942,
     "end_time": "2022-12-30T04:08:26.182361",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.161419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Drop categorical columns that will not be encoded\n",
    "label_X_train = train_X.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = val_X.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# Apply ordinal encoder \n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\n",
    "label_X_valid[good_label_cols] = ordinal_encoder.transform(X_valid[good_label_cols])# Your code here   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60c34868",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:26.199128Z",
     "iopub.status.busy": "2022-12-30T04:08:26.198473Z",
     "iopub.status.idle": "2022-12-30T04:08:26.213162Z",
     "shell.execute_reply": "2022-12-30T04:08:26.211877Z"
    },
    "papermill": {
     "duration": 0.025446,
     "end_time": "2022-12-30T04:08:26.215260",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.189814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 8)\n",
      "Age         141\n",
      "Embarked      2\n",
      "dtype: int64\n",
      "\n",
      " (179, 8)\n",
      "Age    36\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get names of columns with missing values in Xtrain\n",
    "cols_with_missing = [col for col in label_X_train.columns\n",
    "                     if label_X_train[col].isnull().any()]\n",
    "\n",
    "# Shape of training data (num_rows, num_columns)\n",
    "print(label_X_train.shape)\n",
    "\n",
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (label_X_train.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])\n",
    "\n",
    "# Get names of columns with missing values in Valid_X\n",
    "cols_with_missing = [col for col in label_X_valid.columns\n",
    "                     if label_X_valid[col].isnull().any()]\n",
    "\n",
    "# Shape of training data (num_rows, num_columns)\n",
    "print('\\n',label_X_valid.shape)\n",
    "\n",
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (label_X_valid.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c75c53",
   "metadata": {
    "papermill": {
     "duration": 0.0074,
     "end_time": "2022-12-30T04:08:26.230514",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.223114",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Check Absolute Mean Error for Ordinal Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f471999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:26.247438Z",
     "iopub.status.busy": "2022-12-30T04:08:26.247069Z",
     "iopub.status.idle": "2022-12-30T04:08:26.289205Z",
     "shell.execute_reply": "2022-12-30T04:08:26.287824Z"
    },
    "papermill": {
     "duration": 0.053854,
     "end_time": "2022-12-30T04:08:26.291891",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.238037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach (Imputation):\n",
      "0.23626024995539335\n"
     ]
    }
   ],
   "source": [
    "#For Handling Missing Values \n",
    "from sklearn.impute import SimpleImputer\n",
    "# Imputation\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_train = pd.DataFrame(my_imputer.fit_transform(label_X_train))\n",
    "imputed_valid = pd.DataFrame(my_imputer.transform(label_X_valid))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_train.columns = label_X_train.columns\n",
    "imputed_valid.columns = label_X_valid.columns\n",
    "\n",
    "print(\"MAE from Approach (Imputation):\")\n",
    "print(score_dataset(imputed_train, imputed_valid, train_y, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a328c50c",
   "metadata": {
    "papermill": {
     "duration": 0.007747,
     "end_time": "2022-12-30T04:08:26.307411",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.299664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**(One-Hot Encoding)**\n",
    "\n",
    "We use the OneHotEncoder class from scikit-learn to get one-hot encodings. There are a number of parameters that can be used to customize its behavior.\n",
    "\n",
    "We set handle_unknown='ignore' to avoid errors when the validation data contains classes that aren't represented in the training data, and\n",
    "setting sparse=False ensures that the encoded columns are returned as a numpy array (instead of a sparse matrix).\n",
    "To use the encoder, we supply only the categorical columns that we want to be one-hot encoded. For instance, to encode the training data, we supply X_train[object_cols]. (object_cols in the code cell below is a list of the column names with categorical data, and so X_train[object_cols] contains all of the categorical data in the training set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fe88231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:26.324269Z",
     "iopub.status.busy": "2022-12-30T04:08:26.323939Z",
     "iopub.status.idle": "2022-12-30T04:08:26.342014Z",
     "shell.execute_reply": "2022-12-30T04:08:26.340688Z"
    },
    "papermill": {
     "duration": 0.029005,
     "end_time": "2022-12-30T04:08:26.344072",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.315067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 8)\n",
      "(179, 12)\n"
     ]
    }
   ],
   "source": [
    "#Selecting Training Data with categories using oneHot encoder and splitting to train and validation \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "s = (X_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "# features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", 'Embarked','Age']\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "print(X_train.shape)\n",
    "\n",
    "print(OH_X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06045ed",
   "metadata": {
    "papermill": {
     "duration": 0.008081,
     "end_time": "2022-12-30T04:08:26.359713",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.351632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Getting missing values colums from training and validations set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6c258db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:26.376499Z",
     "iopub.status.busy": "2022-12-30T04:08:26.376150Z",
     "iopub.status.idle": "2022-12-30T04:08:26.387144Z",
     "shell.execute_reply": "2022-12-30T04:08:26.385565Z"
    },
    "papermill": {
     "duration": 0.022488,
     "end_time": "2022-12-30T04:08:26.389854",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.367366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 12)\n",
      "Age    141\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get names of columns with missing values in Xtrain\n",
    "cols_with_missing = [col for col in OH_X_train.columns\n",
    "                     if OH_X_train[col].isnull().any()]\n",
    "\n",
    "# Shape of training data (num_rows, num_columns)\n",
    "print(OH_X_train.shape)\n",
    "\n",
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (OH_X_train.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "346f4027",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:26.407583Z",
     "iopub.status.busy": "2022-12-30T04:08:26.406690Z",
     "iopub.status.idle": "2022-12-30T04:08:26.418847Z",
     "shell.execute_reply": "2022-12-30T04:08:26.417329Z"
    },
    "papermill": {
     "duration": 0.023889,
     "end_time": "2022-12-30T04:08:26.421749",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.397860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179, 12)\n",
      "Age    36\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get names of columns with missing values in Valid_X\n",
    "cols_with_missing = [col for col in OH_X_valid.columns\n",
    "                     if OH_X_valid[col].isnull().any()]\n",
    "\n",
    "# Shape of training data (num_rows, num_columns)\n",
    "print(OH_X_valid.shape)\n",
    "\n",
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (OH_X_valid.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daafb46d",
   "metadata": {
    "papermill": {
     "duration": 0.00735,
     "end_time": "2022-12-30T04:08:26.436938",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.429588",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Check Absolute Mean Error for OneHot Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2417657b",
   "metadata": {
    "papermill": {
     "duration": 0.007135,
     "end_time": "2022-12-30T04:08:26.451556",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.444421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Using simple imputer from sklearn to impute values for Xtrain and Xvalid** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ed74273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:26.467893Z",
     "iopub.status.busy": "2022-12-30T04:08:26.467541Z",
     "iopub.status.idle": "2022-12-30T04:08:26.507388Z",
     "shell.execute_reply": "2022-12-30T04:08:26.506416Z"
    },
    "papermill": {
     "duration": 0.050248,
     "end_time": "2022-12-30T04:08:26.509230",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.458982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach (Imputation):\n",
      "0.2279342323975322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "#For Handling Missing Values \n",
    "from sklearn.impute import SimpleImputer\n",
    "# Imputation\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(OH_X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(OH_X_valid))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train.columns = OH_X_train.columns\n",
    "imputed_X_valid.columns = OH_X_valid.columns\n",
    "\n",
    "print(\"MAE from Approach (Imputation):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, train_y, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d0a9dd",
   "metadata": {
    "papermill": {
     "duration": 0.007552,
     "end_time": "2022-12-30T04:08:26.524670",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.517118",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Handling for Xtest Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc124462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:26.542467Z",
     "iopub.status.busy": "2022-12-30T04:08:26.542107Z",
     "iopub.status.idle": "2022-12-30T04:08:26.559584Z",
     "shell.execute_reply": "2022-12-30T04:08:26.558349Z"
    },
    "papermill": {
     "duration": 0.029371,
     "end_time": "2022-12-30T04:08:26.561898",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.532527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be one-hot encoded: ['Sex', 'Embarked']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Cabin', 'Name', 'Ticket']\n",
      "\n",
      "Numerical Columns from the dataset: ['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare'] \n",
      "\n",
      "Categorical variables:\n",
      "['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Sex', 2), ('Embarked', 3)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Selecting X_test data without categorical variables \n",
    "X_test = X_test_full\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "\n",
    "Ts = (X_test.dtypes == 'object')\n",
    "object_test_cols = list(Ts[Ts].index)\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "Tlow_cardinality_cols = [col for col in object_test_cols if X_test[col].nunique() < 10]\n",
    "# Columns that will be dropped from the dataset\n",
    "high_cardinality_cols = list(set(object_test_cols)-set(Tlow_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)\n",
    "\n",
    "\n",
    "#Or you can do this if you know the columns to drop\n",
    "# X.drop(['Name', 'Cabin', 'Ticket'], axis=1, inplace=True)\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_test.columns if X_test[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "print('\\nNumerical Columns from the dataset:', numerical_cols,'\\n')\n",
    "\n",
    "# Keep selected columns only\n",
    "test_cols = Tlow_cardinality_cols + numerical_cols\n",
    "X_test_Run = X_test[test_cols].copy()\n",
    "\n",
    "print(\"Categorical variables:\")\n",
    "print(object_test_cols,'\\n')\n",
    "\n",
    "# # Get number of unique entries in each column with categorical data\n",
    "object_unique = list(map(lambda col: X_test[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_unique))\n",
    "\n",
    "# # Print number of unique entries by column, in ascending order\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1d01e9",
   "metadata": {
    "papermill": {
     "duration": 0.007514,
     "end_time": "2022-12-30T04:08:26.577558",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.570044",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Using one Hot Encoder for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "129c7203",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:26.595748Z",
     "iopub.status.busy": "2022-12-30T04:08:26.595413Z",
     "iopub.status.idle": "2022-12-30T04:08:26.619902Z",
     "shell.execute_reply": "2022-12-30T04:08:26.618463Z"
    },
    "papermill": {
     "duration": 0.036244,
     "end_time": "2022-12-30T04:08:26.621791",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.585547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass   Age  SibSp  Parch     Fare    0    1    2    3    4  \\\n",
       "0          892       3  34.5      0      0   7.8292  0.0  1.0  0.0  1.0  0.0   \n",
       "1          893       3  47.0      1      0   7.0000  1.0  0.0  0.0  0.0  1.0   \n",
       "2          894       2  62.0      0      0   9.6875  0.0  1.0  0.0  1.0  0.0   \n",
       "3          895       3  27.0      0      0   8.6625  0.0  1.0  0.0  0.0  1.0   \n",
       "4          896       3  22.0      1      1  12.2875  1.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "     5  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply one-hot encoder to each column with categorical data\n",
    "Ts = (X_test_Run.dtypes == 'object')\n",
    "object_test_cols = list(Ts[Ts].index)\n",
    "TOH_cols_test = pd.DataFrame(OH_encoder.fit_transform(X_test_Run[object_test_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "TOH_cols_test.index = X_test_Run.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_test = X_test_Run.drop(object_test_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_test = pd.concat([num_X_test, TOH_cols_test], axis=1)\n",
    "OH_X_test['5'] = np.zeros(OH_X_test.shape[0])\n",
    "OH_X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb2cb46d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:26.640031Z",
     "iopub.status.busy": "2022-12-30T04:08:26.639653Z",
     "iopub.status.idle": "2022-12-30T04:08:26.656727Z",
     "shell.execute_reply": "2022-12-30T04:08:26.655363Z"
    },
    "papermill": {
     "duration": 0.028969,
     "end_time": "2022-12-30T04:08:26.659167",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.630198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 12)\n",
      "Age     86\n",
      "Fare     1\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "test_imputer = SimpleImputer()\n",
    "\n",
    "#Checking for missing values\n",
    "cols_with_missing = [col for col in OH_X_test.columns\n",
    "                     if OH_X_test[col].isnull().any()]\n",
    "\n",
    "# Shape of training data (num_rows, num_columns)\n",
    "print(OH_X_test.shape)\n",
    "\n",
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (OH_X_test.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])\n",
    "\n",
    "#Imputing data to the missing numerical data of X_test \n",
    "final_X_test = pd.DataFrame(test_imputer.fit_transform(OH_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1005002c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:26.677435Z",
     "iopub.status.busy": "2022-12-30T04:08:26.677070Z",
     "iopub.status.idle": "2022-12-30T04:08:26.702578Z",
     "shell.execute_reply": "2022-12-30T04:08:26.701698Z"
    },
    "papermill": {
     "duration": 0.036667,
     "end_time": "2022-12-30T04:08:26.704351",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.667684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction of X_Test\n",
    "model = RandomForestRegressor(max_leaf_nodes=100, n_estimators=10,random_state=1)\n",
    "model.fit(imputed_X_valid, val_y)\n",
    "preds = model.predict(final_X_test)\n",
    "preds = (np.floor(preds)).astype(int)\n",
    "preds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f493a49b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:08:26.722920Z",
     "iopub.status.busy": "2022-12-30T04:08:26.722524Z",
     "iopub.status.idle": "2022-12-30T04:08:26.736227Z",
     "shell.execute_reply": "2022-12-30T04:08:26.735038Z"
    },
    "papermill": {
     "duration": 0.025542,
     "end_time": "2022-12-30T04:08:26.738358",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.712816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame({'PassengerId': X_test_full.PassengerId, 'Survived': preds})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d70f194",
   "metadata": {
    "papermill": {
     "duration": 0.008118,
     "end_time": "2022-12-30T04:08:26.755249",
     "exception": false,
     "start_time": "2022-12-30T04:08:26.747131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.041843,
   "end_time": "2022-12-30T04:08:27.385751",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-30T04:08:17.343908",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
