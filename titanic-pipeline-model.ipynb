{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "273e46bc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-30T04:02:15.681154Z",
     "iopub.status.busy": "2022-12-30T04:02:15.680710Z",
     "iopub.status.idle": "2022-12-30T04:02:15.693287Z",
     "shell.execute_reply": "2022-12-30T04:02:15.692091Z"
    },
    "papermill": {
     "duration": 0.022891,
     "end_time": "2022-12-30T04:02:15.696593",
     "exception": false,
     "start_time": "2022-12-30T04:02:15.673702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a926b1d3",
   "metadata": {
    "papermill": {
     "duration": 0.003542,
     "end_time": "2022-12-30T04:02:15.704639",
     "exception": false,
     "start_time": "2022-12-30T04:02:15.701097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Using Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34fd710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:02:15.713729Z",
     "iopub.status.busy": "2022-12-30T04:02:15.713105Z",
     "iopub.status.idle": "2022-12-30T04:02:16.710698Z",
     "shell.execute_reply": "2022-12-30T04:02:16.709678Z"
    },
    "papermill": {
     "duration": 1.004983,
     "end_time": "2022-12-30T04:02:16.713356",
     "exception": false,
     "start_time": "2022-12-30T04:02:15.708373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "train_full_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "\n",
    "#Read Test data\n",
    "X_test_full = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "\n",
    "# Separate target from predictors\n",
    "y = train_full_data[\"Survived\"]\n",
    "X = train_full_data.drop([\"Survived\"], axis=1)\n",
    "\n",
    "# Divide data into training and validation subsets\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 1000 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbe9a19",
   "metadata": {
    "papermill": {
     "duration": 0.003682,
     "end_time": "2022-12-30T04:02:16.721257",
     "exception": false,
     "start_time": "2022-12-30T04:02:16.717575",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We take a peek at the training data with the head() method below. Notice that the data contains both categorical data and columns with missing values. With a pipeline, it's easy to deal with both!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "929c1645",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:02:16.730447Z",
     "iopub.status.busy": "2022-12-30T04:02:16.730068Z",
     "iopub.status.idle": "2022-12-30T04:02:16.751085Z",
     "shell.execute_reply": "2022-12-30T04:02:16.749985Z"
    },
    "papermill": {
     "duration": 0.028312,
     "end_time": "2022-12-30T04:02:16.753361",
     "exception": false,
     "start_time": "2022-12-30T04:02:16.725049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Boulos, Mrs. Joseph (Sultana)</td>\n",
       "      <td>female</td>\n",
       "      <td>2678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>141</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15.2458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>Kvillner, Mr. Johan Henrik Johannesson</td>\n",
       "      <td>male</td>\n",
       "      <td>C.A. 18723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>440</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>Mallet, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>S.C./PARIS 2079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>818</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Betros, Mr. Tannous</td>\n",
       "      <td>male</td>\n",
       "      <td>2648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>379</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>Windelov, Mr. Einar</td>\n",
       "      <td>male</td>\n",
       "      <td>SOTON/OQ 3101317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>492</td>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Name     Sex            Ticket Cabin  \\\n",
       "140           Boulos, Mrs. Joseph (Sultana)  female              2678   NaN   \n",
       "439  Kvillner, Mr. Johan Henrik Johannesson    male        C.A. 18723   NaN   \n",
       "817                      Mallet, Mr. Albert    male   S.C./PARIS 2079   NaN   \n",
       "378                     Betros, Mr. Tannous    male              2648   NaN   \n",
       "491                     Windelov, Mr. Einar    male  SOTON/OQ 3101317   NaN   \n",
       "\n",
       "    Embarked  PassengerId  Pclass   Age  SibSp  Parch     Fare  \n",
       "140        C          141       3   NaN      0      2  15.2458  \n",
       "439        S          440       2  31.0      0      0  10.5000  \n",
       "817        C          818       2  31.0      1      1  37.0042  \n",
       "378        C          379       3  20.0      0      0   4.0125  \n",
       "491        S          492       3  21.0      0      0   7.2500  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f971d",
   "metadata": {
    "papermill": {
     "duration": 0.003728,
     "end_time": "2022-12-30T04:02:16.761203",
     "exception": false,
     "start_time": "2022-12-30T04:02:16.757475",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**We construct the full pipeline in three steps.**\n",
    "\n",
    "Step 1: Define Preprocessing Steps\n",
    "Similar to how a pipeline bundles together preprocessing and modeling steps, we use the ColumnTransformer class to bundle together different preprocessing steps. The code below:\n",
    "\n",
    "imputes missing values in numerical data, and\n",
    "imputes missing values and applies a one-hot encoding to categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "591175bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:02:16.770841Z",
     "iopub.status.busy": "2022-12-30T04:02:16.770156Z",
     "iopub.status.idle": "2022-12-30T04:02:16.887342Z",
     "shell.execute_reply": "2022-12-30T04:02:16.886548Z"
    },
    "papermill": {
     "duration": 0.12478,
     "end_time": "2022-12-30T04:02:16.889888",
     "exception": false,
     "start_time": "2022-12-30T04:02:16.765108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39d21ae",
   "metadata": {
    "papermill": {
     "duration": 0.003745,
     "end_time": "2022-12-30T04:02:16.897987",
     "exception": false,
     "start_time": "2022-12-30T04:02:16.894242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Step 2: Define the Model**\n",
    "\n",
    "Next, we define a random forest model with the familiar RandomForestRegressor class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d24b96d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:02:16.907895Z",
     "iopub.status.busy": "2022-12-30T04:02:16.907127Z",
     "iopub.status.idle": "2022-12-30T04:02:16.980034Z",
     "shell.execute_reply": "2022-12-30T04:02:16.979229Z"
    },
    "papermill": {
     "duration": 0.080717,
     "end_time": "2022-12-30T04:02:16.982574",
     "exception": false,
     "start_time": "2022-12-30T04:02:16.901857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(max_leaf_nodes=100, n_estimators=10, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e645245b",
   "metadata": {
    "papermill": {
     "duration": 0.003948,
     "end_time": "2022-12-30T04:02:16.990788",
     "exception": false,
     "start_time": "2022-12-30T04:02:16.986840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Step 3: Create and Evaluate the Pipeline**\n",
    "\n",
    "Finally, we use the Pipeline class to define a pipeline that bundles the preprocessing and modeling steps. There are a few important things to notice:\n",
    "\n",
    "* With the pipeline, we preprocess the training data and fit the model in a single line of code. (In contrast, without a pipeline, we have to do imputation, one-hot encoding, and model training in separate steps. This becomes especially messy if we have to deal with both numerical and categorical variables!)\n",
    "* With the pipeline, we supply the unprocessed features in X_valid to the predict() command, and the pipeline automatically preprocesses the features before generating predictions. (However, without a pipeline, we have to remember to preprocess the validation data before making predictions.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef4b20a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:02:17.000291Z",
     "iopub.status.busy": "2022-12-30T04:02:16.999922Z",
     "iopub.status.idle": "2022-12-30T04:02:17.158941Z",
     "shell.execute_reply": "2022-12-30T04:02:17.157240Z"
    },
    "papermill": {
     "duration": 0.167571,
     "end_time": "2022-12-30T04:02:17.162271",
     "exception": false,
     "start_time": "2022-12-30T04:02:16.994700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.1776536312849162\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)\n",
    "                             ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "\n",
    "# Evaluate the model\n",
    "score = mean_absolute_error(y_valid, preds)\n",
    "print('MAE:', score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373ff9dc",
   "metadata": {
    "papermill": {
     "duration": 0.003873,
     "end_time": "2022-12-30T04:02:17.170678",
     "exception": false,
     "start_time": "2022-12-30T04:02:17.166805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Predictions on Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "261fe95d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:02:17.180276Z",
     "iopub.status.busy": "2022-12-30T04:02:17.179865Z",
     "iopub.status.idle": "2022-12-30T04:02:17.203139Z",
     "shell.execute_reply": "2022-12-30T04:02:17.201848Z"
    },
    "papermill": {
     "duration": 0.031085,
     "end_time": "2022-12-30T04:02:17.205774",
     "exception": false,
     "start_time": "2022-12-30T04:02:17.174689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = my_pipeline.predict(X_test_full)\n",
    "pred_test = (np.rint(pred_test)).astype(int)\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8a5aa62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T04:02:17.215833Z",
     "iopub.status.busy": "2022-12-30T04:02:17.215479Z",
     "iopub.status.idle": "2022-12-30T04:02:17.229497Z",
     "shell.execute_reply": "2022-12-30T04:02:17.228403Z"
    },
    "papermill": {
     "duration": 0.021521,
     "end_time": "2022-12-30T04:02:17.231634",
     "exception": false,
     "start_time": "2022-12-30T04:02:17.210113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame({'PassengerId': X_test_full.PassengerId, 'Survived': pred_test})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4accefea",
   "metadata": {
    "papermill": {
     "duration": 0.004516,
     "end_time": "2022-12-30T04:02:17.240637",
     "exception": false,
     "start_time": "2022-12-30T04:02:17.236121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.33384,
   "end_time": "2022-12-30T04:02:17.866052",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-30T04:02:06.532212",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
